---
openapi: get /get_stream_status
---

The `get_stream_status` API checks the current status of a streaming process (conversation streaming). This is useful for checking if the streaming process is still active and if a response is generated for the latest message **in case client disconnects** from the stream.

---

## Case 1: Stream not started yet

```js
if (response_processing_status === null && stream_status === 'is_streaming') {
  // code here
}
```

- `stream_status` is "is_streaming" but `response_processing_status` is `null`.
- Meaning: The message is sent for processing, but no response is being processed yet.
- Action taken:
  - Calls `callSourceHandler(token)` (with `temp_token`) to call the `get_response` endpoint to get the response.
  - Shows message loading state.

## Case 2: Stream initialized and processing

```js
else if (response_processing_status === 'processing' && stream_status === 'is_streaming') {
    // code here
}
```

- `stream_status` is "is_streaming" and `response_processing_status` is "processing".
- Meaning: The response is still being generated. No need to call `get_response` endpoint.
- Action taken:

  - Keeps showing the message loading state.
  - Retries `stream_status` status until `MAX_TRIES` is reached or both (`stream_status` and `response_processing_status`) get `completed` whichever first:
    - If retries (tries) are less than `MAX_TRIES`, increase the counter.
    - If retries exceed `MAX_TRIES`, stop loading and stop checking `(clearInterval(intervalId))`.

## Case 3: Stream is completed

```js
else if (response_processing_status === 'completed' && stream_status === 'completed') {
    // assistant response generation completed
    // code here
}
```

- Both `stream_status` and `response_processing_status` are "completed".
- Meaning: The AI Agent has finished generating the response.
- Action taken:

  - Find the latest user message index in both current messages and saved conversation.
  - Collect all assistant messages that appear after the latest user message.
  - Map them into new message objects with timestamp formatting.
  - Replace everything after the latest user message in conversationData with these new assistant messages.

- After processing:
  - Turn off the message loading state
  - Clear polling/interval loop

## Case 4: Unknown / Other status

```js
else {
  clearInterval(intervalId);
}
```

- Any other situation that doesn't match the above cases.
- Meaning: Something unexpected happened or no valid status.
- Action taken:
  - Stops checking by clearing the interval.

**Example:**

```js
const callAgainHandler = async () => {
  const response = await generateSecret(conversationID);
  const token = response.data?.data?.temp_token;
  if (token) {
    callSourceHandler(token);
  }
};

const MAX_TRIES = 20;
const POLL_INTERVAL = 3000; // 3 seconds

const fetchStatus = async () => {
  try {
    const streamStatus = await api.get('/get_stream_status', {
      converstion_id: conversationID,
    });

    if (cancelled) return;

    if (streamStatus?.status === 200) {
      const status = streamStatus.data?.data?.stream_status;
      const response_processing_status = streamStatus.data?.data?.response_processing_status;
      const messages = streamStatus.data?.data?.messages || [];
      const latest5Messages = streamStatus.data?.data?.latest_5 || [];

      if (!response_processing_status && status === 'is_streaming') {
        callAgainHandler();
        // show message loading state here
        clearInterval(intervalId);
      } else if (response_processing_status === 'processing' && status === 'is_streaming') {
        // show message loading state here

        if (tries < MAX_TRIES) {
          // retry polling until MAX_TRIES
          tries++;
        } else if (tries >= MAX_TRIES) {
          setMessageLoading(false);
          clearInterval(intervalId);
        }
      } else if (response_processing_status === 'completed' && status === 'completed') {
        // assistant response generation completed
        const latestUserIndex = messages?.map((m) => m?.role)?.lastIndexOf('user');
        const savedLatestUserIndex = conversationData?.map((m) => m?.role)?.lastIndexOf('user');
        const assistantAfterLatest = messages?.slice(latestUserIndex + 1)?.filter((m) => m?.role === 'assistant');

        if (assistantAfterLatest?.length) {
          console.log('Processing new messages:', assistantAfterLatest?.length);

          const newMessageData = assistantAfterLatest.map((serverMsg) => {
            const istFormattedDate = new Date(serverMsg?.created_at).toLocaleString('en-IN', { timeZone: 'Asia/Kolkata' });
            return {
              content: serverMsg?.content ?? '',
              role: 'assistant',
              time: istFormattedDate,
            };
          });

          setConversationData((prev) => {
            const before = prev?.slice(0, savedLatestUserIndex + 1);
            return [...before, ...newMessageData];
          });
        }

        // turn off message loading state here
        clearInterval(intervalId);
      } else {
        clearInterval(intervalId);
      }
    } else {
      setMessageLoading(false);
      clearInterval(intervalId);
    }
  } catch (err) {
    clearInterval(intervalId);
  }
};

fetchStatus();
intervalId = setInterval(fetchStatus, POLL_INTERVAL);
```
