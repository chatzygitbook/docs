### The Context Window is how much text a model can "see" at once.

| Model | Approx Context Size |
| :--- | :--- |
| GPT-4o / Claude 3.5 | 128K tokens (very large) |
| GPT-4o Mini / Gemini Flash | 32K-64K tokens |
| Older models | 8K-16K tokens |

Larger windows mean:

* More data in a single query
* Better long-form answers

> Change the context window by selecting a different model.